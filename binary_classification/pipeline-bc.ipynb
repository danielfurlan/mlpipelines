{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":16,"outputs":[{"output_type":"stream","text":"/kaggle/input/df-atp/df_atp.csv\n/kaggle/input/predicting-pulsar-starintermediate/pulsar_data_train.csv\n/kaggle/input/predicting-pulsar-starintermediate/pulsar_data_test.csv\n/kaggle/input/data-model4/data_model4.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# __all__ = [\"ColorMode\", \"VisImage\", \"BinaryClass\"]\ndf = pd.read_csv(\"../input/data-model4/data_model4.csv\", index_col=0)\ndf_atp = pd.read_csv(\"../input/df-atp/df_atp.csv\", index_col=0)\nps = pd.read_csv(\"../input/predicting-pulsar-starintermediate/pulsar_data_train.csv\")","execution_count":17,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (12,13,16,17,18,19,25,39) have mixed types.Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class prepa:\n    \n    def __init__(self,dataframe,col=None):\n        \n        self.df = dataframe\n#         if col == None:\n#             self.col = df.columns\n#         else:\n#             self.col = col\n    \n    def col_nan_errors(self,mode):\n        obj_cols = [x for x in self.df.columns[self.df.dtypes.eq(object)]]\n        print(\"You have these columns as object types (thus possibly with errors) : \\n\", obj_cols)\n        \n        cols_str = [x for x in obj_cols if type(self.df[x][0]) == str]\n        #type(coll)\n        \n        \n        print(\"The columns object that are string (will not be considered to 'coerce' and you be removed from the correction) are : \\n\", cols_str)\n        \n        cols_nan = []\n        [cols_nan.append(name) for name,val in self.df.isnull().any().items() if val]\n#         cols_nan = pd.Series(cols_nan)\n        #display(type(cols))\n        ######################cols_nan.drop_duplicates(inplace=True)\n        #display(cols)\n        print(\"The columns that have nan values are : \\n\", cols_nan)\n        \n        print(\"Would you like to preserve any of the other columns?\\nIf yes, please enter 'y'. Otherwhise 'n'\\n\")\n        ans = input()\n        idx1,idx2 = \"\",\"\"\n        col_rem = []\n        \n        if ans=='y':\n            print(\"Please enter the index of the first and last columns (without space!) you want to REMOVE from the correction and press ENTER\\nAlternatively, you can\\\n            write each one with a comma between\")\n            ans2 = input()\n            if ans2.isdigit():\n                idx1 = ans2[0]\n                idx2 = ans2[1]\n            else:\n                col_rem = [x for x in ans2.split(\",\")]\n                \n        all_cols = cols_nan + obj_cols\n        \n        all_cols = pd.Series(all_cols)\n        all_cols.drop_duplicates(inplace=True)\n        \n#         select_cols = []\n        if len(col_rem) != 0:\n            print(\"Lenght col_rem != 0\")\n            select_cols = all_cols.drop([x for x in col_rem])\n        else:\n            select_cols = cols_nan\n            print(\"select_cols : \", select_cols)\n              \n        self.df.loc[:, select_cols] = self.df.loc[:, select_cols].apply(pd.to_numeric, errors='coerce')\n\n        self.df = self.df.dropna(axis=1, how=\"all\")\n        \n        if mode == \"m_max\":\n            for each in select_cols: \n                self.df[each] = self.df[each].fillna(self.df[each].max()) \n        else:\n            if mode == \"m_min\":\n                for each in select_cols: \n                    self.df[each] = self.df[each].fillna(self.df[each].min())\n        return self.df","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer\nfrom sklearn.metrics import confusion_matrix,accuracy_score, roc_curve, auc\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n\nclass GBM:\n    \n\n    def __init__(self,train,valid,test,target):\n        self.train = train\n        self.valid = valid\n        self.test = test\n        self.target = target\n        self.feature_cols = self.train.columns.drop(self.target)\n  \n    def train_GBM(self,over,n):\n\n\n        dtrain = lgb.Dataset(self.train[self.feature_cols], label=self.train[self.target])\n        dvalid = lgb.Dataset(self.valid[self.feature_cols], label=self.valid[self.target])\n    \n        if over:\n            param = {'num_leaves': 31, 'objective': 'binary', \"max_depth\": 3,\n             'metric': 'auc', 'seed': 7, 'reg_alpha':0.8, 'reg_lambda':0.8}\n            print(f\"Regularization : l1 = {param['reg_alpha']}, l2 = {param['reg_lambda']}\")\n        else:\n            param = {'num_leaves': 64, 'objective': 'binary',\n             'metric': 'auc', 'seed': 7}\n            print(f\"No regularization!\")\n        \n        evals_result = {} \n        bst = lgb.train(param, dtrain, num_boost_round=1000, valid_sets=[dvalid,dtrain], \n                    early_stopping_rounds=10, verbose_eval=10, evals_result=evals_result)\n        nameModel = \"Model \" + str(n) +\".txt\"\n        import joblib\n        # save model\n        joblib.dump(bst, nameModel)\n    \n        self.evaluate_GBM(bst,evals_result,n)  \n        \n    def evaluate_GBM(self,bst,evals_result,n):\n    \n        valid_pred = bst.predict(self.valid[self.feature_cols])\n        valid_score = metrics.roc_auc_score(self.valid[self.target], valid_pred)\n    \n        test_pred = bst.predict(self.test[self.feature_cols])\n        test_score = metrics.roc_auc_score(self.test[self.target], test_pred)\n    \n        print(f\"Validation AUC score: {valid_score:.4f}\")\n        print(f\"Test AUC score: {test_score:.4f}\")\n        if valid_score > 0.95:\n            print(\"\\n\\nYou're overfitting. Better rerun with parameter 'over' as 'True'. If already set as so\\\n            it is time to fine tune your model parameters!\\n\\n\")\n    \n        self.plot(evals_result,valid_pred,bst,n)\n    \n    def plot(self,evals_result,valid_pred,bst,n):\n        \n        global conf\n        global auc\n        global roc\n        global y_predictions\n        #global n\n            \n        if evals_result != None:\n            acu[n] = evals_result\n            fig1 = plt.figure(figsize=(45,10))\n        #print('Plot metrics during training... Our metric : ', param[\"metric\"])\n        #print(\"evals_ results : \", evals_result)\n            lgb.plot_metric(evals_result, metric='auc',figsize=(35,10))\n            plt.xlabel('Iterations',fontsize=20)\n            plt.ylabel('auc',fontsize=20)\n            plt.xticks(fontsize=20)\n            plt.yticks(fontsize=20)\n            plt.title(\"AUC during training\",fontsize=20)\n            plt.legend(fontsize=20)\n            plt.show()\n\n\n            ##### CONFUSION MATRIX\n        th = 0.5\n        y_pred_class = valid_pred > th\n        y_predictions[n] = y_pred_class\n        cm = confusion_matrix(self.valid[self.target], y_pred_class)\n        tn, fp, fn, tp = cm.ravel()\n        fpr = fp / (fp + tn)\n        fnr = fn / (tp + fn)\n        tnr = tn / (tn + fp)\n        tpr = tp / (tp + fn)\n        numberModel = n\n        conf[n] = {'fpr':f'{fpr:.3f}','fnr': f'{fnr:.3f}', 'tnr' : f'{tnr:.3f}', \"tpr\": f'{tpr:.3f}'}\n        if n > 1 and fpr != 0 and fnr != 0 and tnr != 0 and tpr != 0:\n            conf[\"ratio \" + str(n) + \"/\" + str(n-1)] = {\"fp\":f'{float(conf[n][\"fpr\"])/float(conf[n-1][\"fpr\"]):.3f}', \\\n                                                        \"fn\":f'{float(conf[n][\"fnr\"])/float(conf[n-1][\"fnr\"]):.3f}', \\\n                                                        \"tn\":f'{float(conf[n][\"tnr\"])/float(conf[n-1][\"tnr\"]):.3f}', \\\n                                                        \"tp\":f'{float(conf[n][\"tpr\"])/float(conf[n-1][\"tpr\"]):.3f}'}\n        \n        fig2 = plt.figure(figsize=(35,10))\n        fig2.add_subplot(1,2,1)\n        sns.heatmap(cm, annot = True, fmt='d', cmap=\"Blues\", vmin = 0.2,linewidths=.5,annot_kws={\"fontsize\": 20}); #cbar_kws={\"fontsize\": 20},annot_kws={\"fontsize\": 20}\n        sns.set(font_scale=2)\n        plt.title('Confusion Matrix',fontsize=20)\n        plt.ylabel('True Class',fontsize=20)\n        plt.xlabel('Predicted Class',fontsize=20)\n        plt.xticks(fontsize=20)\n        plt.yticks(fontsize=20)\n        plt.text(0.1, 0.3, f' FPR: {fpr:.3f}\\n FNR: {fnr:.3f}\\n TNR: {tnr:.3f}\\n TPR: {tpr:.3f}', style='italic',\n        bbox={'facecolor': 'white', 'alpha': 0.7, 'pad': 5}, fontsize=14)\n        \n        \n        #Print Area Under Curve\n        fig2.add_subplot(1,2,2)\n\n        false_positive_rate, recall, thresholds = roc_curve(self.valid[self.target], valid_pred)\n        roc_auc = auc(false_positive_rate, recall)\n        roc[n] = {'fpr':false_positive_rate,'recall':recall}\n        \n        plt.title('Receiver Operating Characteristic (ROC)')\n        for a in range(1,n+1):\n            plt.plot(roc[a]['fpr'], roc[a]['recall'], 'b', label = f'Model {n}')\n            \n#             plt.plot(false_positive_rate, recall, 'b', label = 'AUC = %0.3f' %roc_auc)\n            plt.legend(loc='lower right')\n            plt.plot([0,1], [0,1], 'r--')\n            plt.xlim([0.0,1.0])\n            plt.ylim([0.0,1.0])\n            plt.ylabel('Recall',fontsize=20)\n            plt.xlabel('Fall-out (1-Specificity)',fontsize=20)\n            plt.xticks(fontsize=20)\n            plt.yticks(fontsize=20)\n        \n        plt.show()    \n        display(conf) \n            \n","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom tensorflow import keras\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nclass DNN:\n    \n    def __init__(self,train,valid,test,target,inp_dim):\n        self.train = train\n        self.valid = valid\n        self.test = test\n        self.target = target\n        self.inp_dim = inp_dim\n        \n    def train_DNN(self,n):\n        #global n\n    \n        print(\"\\n\\n You are now running a DNN algorithm!\\n\\n\")\n        #train,valid, test = get_data_splits(dt)\n\n        X = self.train.drop(self.target,axis=1) #[:,0:60].astype(float)\n        Y = self.train[self.target]\n    # define model\n        model = Sequential()\n\n        model.add(Dense(self.inp_dim, activation='relu'))\n        model.add(Dense(60,activation='relu'))#input_dim=60\n        model.add(Dense(1, activation='sigmoid'))    \n        \n        # compile model\n        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n        # Fit the model\n        history = model.fit(X, Y, epochs=10, batch_size=32, verbose=1)\n        \n        # evaluate the model\n        scores = model.evaluate(X, Y, verbose=1)\n        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n        # save model and architecture to single file\n        model.save(\"model.h5\")\n        print(\"Saved model to disk\")\n            \n        #### Get validation scores\n        X_valid = self.valid.drop(self.target,axis=1)\n\n        from sklearn.preprocessing import MinMaxScaler\n\n        y_pred = model.predict_proba(X_valid)\n\n    #     print(\"lenght ynew : \", len(y_pred))\n    # print(\"X=%s, Predicted=%s\" % (Xnew.iloc[0], ynew[0]))\n\n    #### Plot Accuracy graph:\n        #print(history.history.keys())\n        fig = plt.figure(figsize=(35,10))\n    # history.history['accuracy']\n        plt.plot(history.history['accuracy'], color='blue', label='train')\n\n        plt.xlabel('Epochs',fontsize=20)\n        plt.ylabel('auc',fontsize=20)\n        plt.xticks(fontsize=20)\n        plt.yticks(fontsize=20)\n        plt.title(\"AUC during training\",fontsize=20)\n        plt.legend(fontsize=20)\n\n        plt.show()","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer\nfrom sklearn.metrics import confusion_matrix,accuracy_score, roc_curve, auc\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n\n#import binGBM as gbm\n#import binDNN as dnn\nconf = {}\nacu = {}\nroc = {}\ny_predictions = {}\n\n\nclass BinaryClass:\n    \n    def __init__(self,dataframe,target=None,feature_cols=None):\n        \n        self.dataframe = dataframe\n#         self.conf = {}\n#         self.acu = {}\n#         self.roc = {}\n#         self.y_predictions = {}\n        \n        if target == None:\n            print(\"What is your target columns?\")\n            display(self.dataframe.columns)\n            \n            ans = str(input())\n            while ans not in self.dataframe.columns:\n                print(\"Please, enter a valid column name! Pay attention with spaces!\")\n                ans = str(input())\n            self.target = ans\n            self.feature_cols = dataframe.columns.drop(self.target)\n        else:\n            self.target = target\n            self.feature_cols = dataframe.columns.drop(self.target)\n        \n        self.train, self.valid, self.test = self.get_data_splits(self.dataframe)\n        \n    def get_data_splits(self,dataframe, valid_fraction=0.1):\n        \n        valid_fraction = 0.1\n        valid_size = int(len(dataframe) * valid_fraction)\n\n        train = dataframe[:-valid_size * 2]\n        # valid size == test size, last two sections of the data\n        valid = dataframe[-valid_size * 2:-valid_size]\n        test = dataframe[-valid_size:]\n        print(f\"Train size : {len(train)}\\nValidation size : {len(valid)}\\nTest size : {len(test)}\")\n        return train, valid, test\n    \n    def train_models(self,over,n):\n        gbm = GBM(self.train,self.valid,self.test,self.target)\n#         dnn = DNN()\n        \n        gbm.train_GBM(over,n)\n        print(\"Lenght of self.featcols = \", len(self.feature_cols))\n        print(\"Do you want to run a DNN algorithm? (y/n)\" )\n        answer = input()\n        if answer == 'y':\n            dnn = DNN(self.train,self.valid,self.test,self.target,len(self.feature_cols))\n            dnn.train_DNN(n)\n        \n        ","execution_count":21,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check first for NaN values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"ps.isnull().any()","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":" Mean of the integrated profile                  False\n Standard deviation of the integrated profile    False\n Excess kurtosis of the integrated profile        True\n Skewness of the integrated profile              False\n Mean of the DM-SNR curve                        False\n Standard deviation of the DM-SNR curve           True\n Excess kurtosis of the DM-SNR curve             False\n Skewness of the DM-SNR curve                     True\ntarget_class                                     False\ndtype: bool"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Process all the columns and replace them with the Max (\"m_max\") value of each column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"ps = prepa(ps).col_nan_errors(\"m_max\")","execution_count":23,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'm_max' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-b98c68485fcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_nan_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'm_max' is not defined"]}]},{"metadata":{},"cell_type":"markdown","source":"Check again for the NaN values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"ps.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train & evaluate a Binary Classifier passing the dataframe and the output column name (here is \"target_class\"). If you don't know yet the name of the target name, leave blank and the algorithm will output the options so to you choose interactevely!"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\ndataframe = ps, the dataframe you want to train\ntarget = target_class, the name of your column target!\n\"\"\"\n\nbc = BinaryClass(ps,'target_class')\n\n\"\"\"\nover = False, for overfitting or not\nn = 1, the model number to get and save the results for further comparison\n\"\"\"\nbc.train_models(False,1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Try with other parameters to see the plot comparison in the ROC curve and the dictionary (*conf*) of False/Positve cases rates ratio for each model! "},{"metadata":{"trusted":true},"cell_type":"code","source":"bc.train_models(True,2)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}